{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "      <th>node1_string_id</th>\n",
       "      <th>node2_string_id</th>\n",
       "      <th>homology</th>\n",
       "      <th>experimentally_determined_interaction</th>\n",
       "      <th>database_annotated</th>\n",
       "      <th>automated_textmining</th>\n",
       "      <th>combined_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AP1B1</td>\n",
       "      <td>HIP1R</td>\n",
       "      <td>9606.ENSP00000350199</td>\n",
       "      <td>9606.ENSP00000253083</td>\n",
       "      <td>0</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AP1B1</td>\n",
       "      <td>CLVS2</td>\n",
       "      <td>9606.ENSP00000350199</td>\n",
       "      <td>9606.ENSP00000275162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASPSCR1</td>\n",
       "      <td>UFD1L</td>\n",
       "      <td>9606.ENSP00000306625</td>\n",
       "      <td>9606.ENSP00000263202</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASPSCR1</td>\n",
       "      <td>UBXN7</td>\n",
       "      <td>9606.ENSP00000306625</td>\n",
       "      <td>9606.ENSP00000296328</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASPSCR1</td>\n",
       "      <td>NSFL1C</td>\n",
       "      <td>9606.ENSP00000306625</td>\n",
       "      <td>9606.ENSP00000418529</td>\n",
       "      <td>0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     node1   node2       node1_string_id       node2_string_id  homology  \\\n",
       "0    AP1B1   HIP1R  9606.ENSP00000350199  9606.ENSP00000253083         0   \n",
       "1    AP1B1   CLVS2  9606.ENSP00000350199  9606.ENSP00000275162         0   \n",
       "2  ASPSCR1   UFD1L  9606.ENSP00000306625  9606.ENSP00000263202         0   \n",
       "3  ASPSCR1   UBXN7  9606.ENSP00000306625  9606.ENSP00000296328         0   \n",
       "4  ASPSCR1  NSFL1C  9606.ENSP00000306625  9606.ENSP00000418529         0   \n",
       "\n",
       "   experimentally_determined_interaction  database_annotated  \\\n",
       "0                                  0.131                 0.6   \n",
       "1                                  0.000                 0.6   \n",
       "2                                  0.438                 0.0   \n",
       "3                                  0.472                 0.0   \n",
       "4                                  0.747                 0.0   \n",
       "\n",
       "   automated_textmining  combined_score  \n",
       "0                     0           0.637  \n",
       "1                     0           0.600  \n",
       "2                     0           0.438  \n",
       "3                     0           0.472  \n",
       "4                     0           0.747  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('string-network-1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of nodes\n",
    "\n",
    "nodes = df.node1.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AP1B1', 'ASPSCR1', 'ATP6V1A', 'ATP6V1B2', 'ATP6V1D', 'ATP6V1E1',\n",
       "       'ATP6V1F', 'ATP6V1G1', 'ATP6V1H', 'B2M', 'CALR', 'CD1B', 'CD1D',\n",
       "       'CD8A', 'CHMP2A', 'CHMP2B', 'CHMP3', 'CHMP4B', 'CLVS2', 'DERL1',\n",
       "       'GGA1', 'HGS', 'HIP1R', 'HLA-A', 'HLA-B', 'HLA-C', 'HLA-E',\n",
       "       'HLA-G', 'KLRC1', 'KLRD1', 'KPNA1', 'KPNA2', 'KPNB1', 'NSFL1C',\n",
       "       'NUTF2', 'RAB5A', 'RAB7A', 'RAN', 'STAM', 'TSG101', 'UBXN7',\n",
       "       'UFD1L', 'VCP', 'VPS33B', 'XPO1', 'XPO5'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dict of node inputs\n",
    "\n",
    "node_inputs = {}\n",
    "for node in nodes:\n",
    "    inputs = list(df[df.node1 == node].node2)\n",
    "    node_inputs[node] = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct boolean rules as list\n",
    "rules = []\n",
    "for key, value in node_inputs.items():\n",
    "    rule = key + ' *= '\n",
    "    rule = rule + ' and '.join(value)\n",
    "    rules.append(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct initial conditions\n",
    "initial_conditions = []\n",
    "for node in nodes:\n",
    "    initial_condition = node + ' = Random'\n",
    "    initial_conditions.append(initial_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export model\n",
    "definition = '#initial conditions\\n'+'\\n'.join(initial_conditions)+'\\n\\n#rules\\n'+'\\n'.join(rules)\n",
    "fp = open('model.txt', 'w')\n",
    "fp.write(definition)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = file('model.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  print(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write export helper functions\n",
    "\n",
    "def string2definition1(tabular_text_output, initial_node_value, out='model.txt'):\n",
    "    df = pd.read_csv(tabular_text_output)\n",
    "    \n",
    "    # get list of nodes\n",
    "    nodes = df.node1.unique()\n",
    "    \n",
    "    # build dict of node inputs\n",
    "    node_inputs = {}\n",
    "    for node in nodes:\n",
    "        inputs = list(df[df.node1 == node].node2)\n",
    "        node_inputs[node] = inputs\n",
    "        \n",
    "    # construct boolean rules as list\n",
    "    rules = []\n",
    "    for key, value in node_inputs.items():\n",
    "        rule = key + ' *= '\n",
    "        rule = rule + ' or '.join(value)\n",
    "        rules.append(rule)\n",
    "        \n",
    "    # construct initial conditions\n",
    "    initial_conditions = []\n",
    "    for node in nodes:\n",
    "        initial_condition = node + ' = ' + initial_node_value\n",
    "        initial_conditions.append(initial_condition)\n",
    "        \n",
    "    # definition\n",
    "    definition = '#initial conditions\\n'+'\\n'.join(initial_conditions)+'\\n\\n#rules\\n'+'\\n'.join(rules)\n",
    "\n",
    "#     # export\n",
    "#     fp = open(out, 'w+')\n",
    "#     fp.write(definition)\n",
    "#     fp.close()\n",
    "    \n",
    "    return definition\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_process_edgelist1(definition, edgelist, initial_process_value):\n",
    "    df = pd.read_csv(edgelist)\n",
    "    \n",
    "    # get list of nodes\n",
    "    nodes = df.process.unique()\n",
    "\n",
    "    # build dict of node inputs\n",
    "    node_inputs = {}\n",
    "    for node in nodes:\n",
    "        inputs = list(df[df.process == node].node)\n",
    "        node_inputs[node] = inputs\n",
    "        \n",
    "    # construct boolean rules as list\n",
    "    rules = []\n",
    "    for key, value in node_inputs.items():\n",
    "        rule = key + ' *= '\n",
    "        rule = rule + ' and '.join(value)\n",
    "        rules.append(rule)\n",
    "        \n",
    "    # construct initial conditions\n",
    "    initial_conditions = []\n",
    "    for node in nodes:\n",
    "        initial_condition = node + ' = ' + initial_process_value\n",
    "        initial_conditions.append(initial_condition)\n",
    "        \n",
    "    # definition\n",
    "    return definition + '\\n\\n#process node initial conditions\\n'+'\\n'.join(initial_conditions)+'\\n\\n#process node rules\\n'+'\\n'.join(rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mtb_edgelist(definition, edgelist, initial_mtb_value):\n",
    "    df = pd.read_csv(edgelist)\n",
    "\n",
    "    # get list of nodes\n",
    "    target_nodes = df.node.unique()\n",
    "    mtb_nodes = df.mtb.unique()\n",
    "    \n",
    "    # build dict of node inputs\n",
    "    node_inputs = {}\n",
    "    for node in target_nodes:\n",
    "        inputs = list(df[df.node == node].mtb)\n",
    "        node_inputs[node] = inputs\n",
    "    \n",
    "    # construct boolean rules as list\n",
    "    rules = []\n",
    "    for key, value in node_inputs.items():\n",
    "        rule = key + ' *= ' + key\n",
    "        rule = rule + ' and not (' +' or '.join(value) + ')'\n",
    "        rules.append(rule)\n",
    "\n",
    "    # construct initial conditions\n",
    "    initial_conditions = []\n",
    "    for node in mtb_nodes:\n",
    "        initial_condition = node + ' = ' + initial_mtb_value\n",
    "        initial_conditions.append(initial_condition)\n",
    "        \n",
    "    # definition\n",
    "    return definition + '\\n\\n#mtb node initial conditions\\n'+'\\n'.join(initial_conditions)+'\\n\\n#mtb update rules\\n'+'\\n'.join(rules)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ESCRT_complexes', 'MHC_I_complexes', 'vATPase_complexes'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in complexes and create a dict\n",
    "# build dict of node inputs\n",
    "\n",
    "df_complexes = pd.read_csv('string-1-complexes.csv')\n",
    "complexes = df_complexes.complex.unique()\n",
    "complexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ESCRT_complexes': ['HGS',\n",
       "  'CHMP2A',\n",
       "  'CHMP4B',\n",
       "  'CHMP2B',\n",
       "  'CHMP3',\n",
       "  'STAM',\n",
       "  'TSG101'],\n",
       " 'MHC_I_complexes': ['B2M',\n",
       "  'HLA-C',\n",
       "  'HLA-B',\n",
       "  'HLA-G',\n",
       "  'HLA-E',\n",
       "  'CD8A',\n",
       "  'CALR',\n",
       "  'HLA-A'],\n",
       " 'vATPase_complexes': ['ATP6V1F',\n",
       "  'ATP6V1B2',\n",
       "  'ATP6V1A',\n",
       "  'ATP6V1G1',\n",
       "  'ATP6V1D',\n",
       "  'ATP6V1E1',\n",
       "  'ATP6V1H']}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_inputs = {}\n",
    "for complex in complexes:\n",
    "    inputs = list(df_complexes[df_complexes.complex == complex].node)\n",
    "    complex_inputs[complex] = inputs\n",
    "complex_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AP1B1': ['CLVS2', 'HIP1R'],\n",
       " 'ASPSCR1': ['VCP', 'UBXN7', 'UFD1L', 'NSFL1C'],\n",
       " 'CD1B': ['CD1D', 'MHC_I_complexes'],\n",
       " 'CD1D': ['MHC_I_complexes', 'CD1B'],\n",
       " 'CLVS2': ['AP1B1'],\n",
       " 'DERL1': ['VCP', 'MHC_I_complexes'],\n",
       " 'GGA1': ['RAB5A'],\n",
       " 'HIP1R': ['AP1B1', 'ESCRT_complexes'],\n",
       " 'KLRC1': ['MHC_I_complexes', 'KLRD1'],\n",
       " 'KLRD1': ['KLRC1', 'MHC_I_complexes'],\n",
       " 'KPNA1': ['RAN', 'KPNB1'],\n",
       " 'KPNA2': ['NUTF2', 'RAN', 'KPNB1', 'MHC_I_complexes'],\n",
       " 'KPNB1': ['NUTF2', 'RAN', 'KPNA2', 'KPNA1'],\n",
       " 'NSFL1C': ['VCP', 'ASPSCR1', 'UBXN7', 'UFD1L'],\n",
       " 'NUTF2': ['RAN', 'KPNB1', 'KPNA2'],\n",
       " 'RAB5A': ['GGA1', 'RAB7A'],\n",
       " 'RAB7A': ['ESCRT_complexes', 'RAB5A'],\n",
       " 'RAN': ['NUTF2', 'XPO1', 'XPO5', 'KPNB1', 'KPNA2', 'KPNA1'],\n",
       " 'UBXN7': ['VCP', 'ASPSCR1', 'vATPase_complexes', 'UFD1L', 'NSFL1C'],\n",
       " 'UFD1L': ['VCP', 'VPS33B', 'ASPSCR1', 'UBXN7', 'NSFL1C'],\n",
       " 'VCP': ['ASPSCR1', 'MHC_I_complexes', 'DERL1', 'NSFL1C', 'UBXN7', 'UFD1L'],\n",
       " 'VPS33B': ['UFD1L'],\n",
       " 'XPO1': ['RAN', 'ESCRT_complexes'],\n",
       " 'XPO5': ['RAN']}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_inputs\n",
    "\n",
    "def reduce_complexes(node_inputs, complex_inputs):\n",
    "    # remove nodes in a complex\n",
    "    for components in complex_inputs.values():\n",
    "        for node in node_inputs.keys():\n",
    "            if node in components:\n",
    "                del node_inputs[node]\n",
    "                continue\n",
    "\n",
    "    # replace complex nodes\n",
    "    for node, inputs in node_inputs.items():\n",
    "        for complex, components in complex_inputs.items():\n",
    "            for i, input in enumerate(inputs):\n",
    "                if input in components:\n",
    "                    node_inputs[node][i] = complex\n",
    "                    continue\n",
    "        node_inputs[node] = list(set(node_inputs[node]))\n",
    "    return node_inputs\n",
    "\n",
    "node_inputs # get OR'd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ESCRT_complexes': ['HGS',\n",
       "  'CHMP2A',\n",
       "  'CHMP4B',\n",
       "  'CHMP2B',\n",
       "  'CHMP3',\n",
       "  'STAM',\n",
       "  'TSG101'],\n",
       " 'MHC_I_complexes': ['B2M',\n",
       "  'HLA-C',\n",
       "  'HLA-B',\n",
       "  'HLA-G',\n",
       "  'HLA-E',\n",
       "  'CD8A',\n",
       "  'CALR',\n",
       "  'HLA-A'],\n",
       " 'vATPase_complexes': ['ATP6V1F',\n",
       "  'ATP6V1B2',\n",
       "  'ATP6V1A',\n",
       "  'ATP6V1G1',\n",
       "  'ATP6V1D',\n",
       "  'ATP6V1E1',\n",
       "  'ATP6V1H']}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_inputs # get AND'd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write export helper functions\n",
    "\n",
    "def string2definition2(tabular_text_output, complexes, initial_value):\n",
    "    df = pd.read_csv(tabular_text_output)\n",
    "    df_complexes = pd.read_csv('string-1-complexes.csv')\n",
    "\n",
    "    # get list of nodes \n",
    "    nodes = list(df.node1.unique())\n",
    "    \n",
    "    # build dict of node inputs\n",
    "    node_inputs = {}\n",
    "    for node in nodes:\n",
    "        inputs = list(df[df.node1 == node].node2)\n",
    "        node_inputs[node] = inputs\n",
    "        \n",
    "    # get list of complexes \n",
    "    complexes = list(df_complexes.complex.unique())\n",
    "\n",
    "    # build dict of complexes\n",
    "    complex_inputs = {}\n",
    "    for complex in complexes:\n",
    "        inputs = list(df_complexes[df_complexes.complex == complex].node)\n",
    "        complex_inputs[complex] = inputs\n",
    "\n",
    "    # reduce complexes\n",
    "    node_inputs = reduce_complexes(node_inputs, complex_inputs)\n",
    "    \n",
    "    # OR the nodes\n",
    "    rules = []\n",
    "    for key, value in node_inputs.items():\n",
    "        rule = key + ' *= '\n",
    "        rule = rule + ' or '.join(value)\n",
    "        rules.append(rule)\n",
    "        \n",
    "    # AND the complexes\n",
    "    for key, value in complex_inputs.items():\n",
    "        rule = key + ' *= '\n",
    "        rule = rule + ' and '.join(value)\n",
    "        rules.append(rule)\n",
    "        \n",
    "    # initial conditions\n",
    "    initial_value = 'True' if initial_value else 'False'\n",
    "    initial_conditions = []\n",
    "    for node in (nodes+complexes):\n",
    "        initial_condition = node + ' = ' + initial_value\n",
    "        initial_conditions.append(initial_condition)\n",
    "        \n",
    "    # definition\n",
    "    definition = '#initial conditions\\n'+'\\n'.join(initial_conditions)+'\\n\\n#rules\\n'+'\\n'.join(rules)\n",
    "    \n",
    "    return definition\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "definition2 = string2definition2('string-network-1.csv', 'string-1-complexes.csv', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_process_edgelist2(definition, edgelist, complexes, initial_value):\n",
    "    df = pd.read_csv(edgelist)\n",
    "    \n",
    "    # get list of nodes\n",
    "    nodes = df.process.unique()\n",
    "\n",
    "    # build dict of node inputs\n",
    "    node_inputs = {}\n",
    "    for node in nodes:\n",
    "        inputs = list(df[df.process == node].node)\n",
    "        node_inputs[node] = inputs\n",
    "    \n",
    "    # get list of complexes \n",
    "    complexes = list(df_complexes.complex.unique())\n",
    "\n",
    "    # build dict of complexes\n",
    "    complex_inputs = {}\n",
    "    for complex in complexes:\n",
    "        inputs = list(df_complexes[df_complexes.complex == complex].node)\n",
    "        complex_inputs[complex] = inputs\n",
    "    \n",
    "    # reduce complexes\n",
    "    node_inputs = reduce_complexes(node_inputs, complex_inputs)\n",
    "    \n",
    "    # construct boolean rules as list\n",
    "    rules = []\n",
    "    for key, value in node_inputs.items():\n",
    "        rule = key + ' *= '\n",
    "        rule = rule + ' and '.join(value)\n",
    "        rules.append(rule)\n",
    "        \n",
    "    # initial conditions\n",
    "    initial_value = 'True' if initial_value else 'False'\n",
    "    initial_conditions = []\n",
    "    for node in (nodes):\n",
    "        initial_condition = node + ' = ' + initial_value\n",
    "        initial_conditions.append(initial_condition)\n",
    "        \n",
    "    # definition\n",
    "    return definition + '\\n\\n#process node initial conditions\\n'+'\\n'.join(initial_conditions)+'\\n\\n#process node rules\\n'+'\\n'.join(rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#initial conditions\n",
      "AP1B1 = True\n",
      "ASPSCR1 = True\n",
      "ATP6V1A = True\n",
      "ATP6V1B2 = True\n",
      "ATP6V1D = True\n",
      "ATP6V1E1 = True\n",
      "ATP6V1F = True\n",
      "ATP6V1G1 = True\n",
      "ATP6V1H = True\n",
      "B2M = True\n",
      "CALR = True\n",
      "CD1B = True\n",
      "CD1D = True\n",
      "CD8A = True\n",
      "CHMP2A = True\n",
      "CHMP2B = True\n",
      "CHMP3 = True\n",
      "CHMP4B = True\n",
      "CLVS2 = True\n",
      "DERL1 = True\n",
      "GGA1 = True\n",
      "HGS = True\n",
      "HIP1R = True\n",
      "HLA-A = True\n",
      "HLA-B = True\n",
      "HLA-C = True\n",
      "HLA-E = True\n",
      "HLA-G = True\n",
      "KLRC1 = True\n",
      "KLRD1 = True\n",
      "KPNA1 = True\n",
      "KPNA2 = True\n",
      "KPNB1 = True\n",
      "NSFL1C = True\n",
      "NUTF2 = True\n",
      "RAB5A = True\n",
      "RAB7A = True\n",
      "RAN = True\n",
      "STAM = True\n",
      "TSG101 = True\n",
      "UBXN7 = True\n",
      "UFD1L = True\n",
      "VCP = True\n",
      "VPS33B = True\n",
      "XPO1 = True\n",
      "XPO5 = True\n",
      "ESCRT_complexes = True\n",
      "MHC_I_complexes = True\n",
      "vATPase_complexes = True\n",
      "\n",
      "#rules\n",
      "NUTF2 *= RAN or KPNB1 or KPNA2\n",
      "CD1D *= MHC_I_complexes or CD1B\n",
      "KLRD1 *= KLRC1 or MHC_I_complexes\n",
      "CD1B *= CD1D or MHC_I_complexes\n",
      "HIP1R *= AP1B1 or ESCRT_complexes\n",
      "XPO1 *= RAN or ESCRT_complexes\n",
      "XPO5 *= RAN\n",
      "VPS33B *= UFD1L\n",
      "RAN *= NUTF2 or XPO1 or XPO5 or KPNB1 or KPNA2 or KPNA1\n",
      "DERL1 *= VCP or MHC_I_complexes\n",
      "NSFL1C *= VCP or ASPSCR1 or UBXN7 or UFD1L\n",
      "AP1B1 *= CLVS2 or HIP1R\n",
      "UBXN7 *= VCP or ASPSCR1 or vATPase_complexes or UFD1L or NSFL1C\n",
      "KLRC1 *= MHC_I_complexes or KLRD1\n",
      "RAB7A *= ESCRT_complexes or RAB5A\n",
      "RAB5A *= GGA1 or RAB7A\n",
      "KPNA1 *= RAN or KPNB1\n",
      "KPNB1 *= NUTF2 or RAN or KPNA2 or KPNA1\n",
      "GGA1 *= RAB5A\n",
      "VCP *= ASPSCR1 or MHC_I_complexes or DERL1 or NSFL1C or UBXN7 or UFD1L\n",
      "ASPSCR1 *= VCP or UBXN7 or UFD1L or NSFL1C\n",
      "KPNA2 *= NUTF2 or RAN or KPNB1 or MHC_I_complexes\n",
      "UFD1L *= VCP or VPS33B or ASPSCR1 or UBXN7 or NSFL1C\n",
      "CLVS2 *= AP1B1\n",
      "vATPase_complexes *= ATP6V1F and ATP6V1B2 and ATP6V1A and ATP6V1G1 and ATP6V1D and ATP6V1E1 and ATP6V1H\n",
      "ESCRT_complexes *= HGS and CHMP2A and CHMP4B and CHMP2B and CHMP3 and STAM and TSG101\n",
      "MHC_I_complexes *= B2M and HLA-C and HLA-B and HLA-G and HLA-E and CD8A and CALR and HLA-A\n",
      "\n",
      "#process node initial conditions\n",
      "Phagosome_acidification = True\n",
      "Phagosome_maturation = True\n",
      "Phagolysosome_assembly = True\n",
      "\n",
      "#process node rules\n",
      "Phagosome_maturation *= RAB7A and CORO1A and vATPase_complexes\n",
      "Phagosome_acidification *= RAB7A and vATPase_complexes\n",
      "Phagolysosome_assembly *= RAB7A and CORO1A\n"
     ]
    }
   ],
   "source": [
    "print add_process_edgelist2(definition2, 'string-1-process-edgelist.csv', 'string-1-complexes.csv', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rp1",
   "language": "python",
   "name": "rp1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
