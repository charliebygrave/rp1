{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('string-network-1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of nodes\n",
    "\n",
    "nodes = df.node1.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dict of node inputs\n",
    "\n",
    "node_inputs = {}\n",
    "for node in nodes:\n",
    "    inputs = list(df[df.node1 == node].node2)\n",
    "    node_inputs[node] = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct boolean rules as list\n",
    "rules = []\n",
    "for key, value in node_inputs.items():\n",
    "    rule = key + ' *= '\n",
    "    rule = rule + ' and '.join(value)\n",
    "    rules.append(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct initial conditions\n",
    "initial_conditions = []\n",
    "for node in nodes:\n",
    "    initial_condition = node + ' = Random'\n",
    "    initial_conditions.append(initial_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export model\n",
    "definition = '#initial conditions\\n'+'\\n'.join(initial_conditions)+'\\n\\n#rules\\n'+'\\n'.join(rules)\n",
    "fp = open('model.txt', 'w')\n",
    "fp.write(definition)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = file('model.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  print(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string2definition(tabular_text_output, initial_value):\n",
    "    \"\"\"\n",
    "    model 1\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(tabular_text_output)\n",
    "    \n",
    "    # get list of nodes\n",
    "    nodes = df.node1.unique()\n",
    "    \n",
    "    # build dict of node inputs\n",
    "    node_inputs = {}\n",
    "    for node in nodes:\n",
    "        inputs = list(df[df.node1 == node].node2)\n",
    "        node_inputs[node] = inputs\n",
    "        \n",
    "    # construct boolean rules as list\n",
    "    rules = []\n",
    "    for key, value in node_inputs.items():\n",
    "        rule = key + ' *= '\n",
    "        rule = rule + ' or '.join(value)\n",
    "        rules.append(rule)\n",
    "        \n",
    "    # construct initial conditions\n",
    "    initial_conditions = []\n",
    "    initial_value = 'True' if initial_value else 'False'\n",
    "    for node in nodes:\n",
    "        initial_condition = node + ' = ' + initial_value\n",
    "        initial_conditions.append(initial_condition)\n",
    "        \n",
    "    # definition\n",
    "    return (\n",
    "        '#initial conditions\\n'+\n",
    "        '\\n'.join(initial_conditions)+         \n",
    "        '\\n\\n'+\n",
    "        '#rules\\n'+\n",
    "        '\\n'.join(rules)\n",
    "    )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_process_edgelist(definition, edgelist, initial_value):\n",
    "    \"\"\"\n",
    "    model 1\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(edgelist)\n",
    "    \n",
    "    # get list of nodes\n",
    "    nodes = df.process.unique()\n",
    "\n",
    "    # build dict of node inputs\n",
    "    node_inputs = {}\n",
    "    for node in nodes:\n",
    "        inputs = list(df[df.process == node].node)\n",
    "        node_inputs[node] = inputs\n",
    "    \n",
    "    # remove input nodes not in the network (not modelled)\n",
    "    for inputs in node_inputs.values():\n",
    "        for input in inputs:\n",
    "            if input not in definition: inputs.remove(input)\n",
    "\n",
    "    # construct boolean rules as list\n",
    "    rules = []\n",
    "    for key, value in node_inputs.items():\n",
    "        rule = key + ' *= '\n",
    "        rule = rule + ' and '.join(value)\n",
    "        rules.append(rule)\n",
    "        \n",
    "    # construct initial conditions\n",
    "    initial_conditions = []\n",
    "    initial_value = 'True' if initial_value else 'False'\n",
    "    for node in nodes:\n",
    "        initial_condition = node + ' = ' + initial_value\n",
    "        initial_conditions.append(initial_condition)\n",
    "        \n",
    "    # definition\n",
    "    return (\n",
    "        definition + \n",
    "        '\\n\\n'+\n",
    "        '#process node initial conditions\\n'+\n",
    "        '\\n'.join(initial_conditions)+\n",
    "        '\\n\\n'+\n",
    "        '#process node rules\\n'+\n",
    "        '\\n'.join(rules)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mtb_edgelist(definition, mtb_edgelist, initial_value):\n",
    "    \"\"\"\n",
    "    model 1\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(mtb_edgelist)\n",
    "\n",
    "    # get list of nodes\n",
    "    target_nodes = df.node.unique()\n",
    "    \n",
    "    # build dict of node inputs\n",
    "    node_inputs = {}\n",
    "    for node in target_nodes:\n",
    "        inputs = list(df[df.node == node].mtb)\n",
    "        node_inputs[node] = inputs\n",
    "    \n",
    "    # remove factors without target nodes in the network (not modelled)\n",
    "    mtb_nodes = []\n",
    "    for node, mtb in node_inputs.items():\n",
    "        if node not in definition:\n",
    "            del node_inputs[node]\n",
    "        else:\n",
    "            mtb_nodes+=mtb\n",
    "            mtb_nodes = list(set(mtb_nodes)) #unique values\n",
    "\n",
    "    # construct boolean rules as list\n",
    "    rules = []\n",
    "    for target_node, mtb in node_inputs.items():\n",
    "        rule = target_node + ' *= ' + target_node # add the inhibition rule recursively\n",
    "        rule = rule + ' and not (' +' or '.join(mtb) + ')'\n",
    "        rules.append(rule)\n",
    "\n",
    "    # construct initial conditions\n",
    "    initial_conditions = []\n",
    "    initial_value = 'True' if initial_value else 'False'\n",
    "    for node in mtb_nodes:\n",
    "        initial_condition = node + ' = ' + initial_value\n",
    "        initial_conditions.append(initial_condition)\n",
    "        \n",
    "    # definition\n",
    "    return (\n",
    "        definition + \n",
    "        '\\n\\n'+\n",
    "        '#mtb node initial conditions\\n'+\n",
    "        '\\n'.join(initial_conditions)+\n",
    "        '\\n\\n'+\n",
    "        '#mtb update rules\\n'+\n",
    "        '\\n'.join(rules)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definition = string2definition('string-network-1.csv', True)\n",
    "definition = add_process_edgelist(definition,'string-1-process-edgelist.csv', True)\n",
    "print add_mtb_edgelist(definition, 'mtb-edgelist.csv', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in complexes and create a dict\n",
    "# build dict of node inputs\n",
    "\n",
    "df_complexes = pd.read_csv('string-1-complexes.csv')\n",
    "complexes = df_complexes.complex.unique()\n",
    "complexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_components = {}\n",
    "for complex in complexes:\n",
    "    inputs = list(df_complexes[df_complexes.complex == complex].node)\n",
    "    complex_components[complex] = inputs\n",
    "complex_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_inputs\n",
    "\n",
    "def reduce_complexes(node_inputs, complex_components):\n",
    "    # remove nodes in a complex\n",
    "    for components in complex_components.values():\n",
    "        for node in node_inputs.keys():\n",
    "            if node in components:\n",
    "                del node_inputs[node]\n",
    "                continue\n",
    "\n",
    "    # replace complex nodes\n",
    "    for node, inputs in node_inputs.items():\n",
    "        for complex, components in complex_components.items():\n",
    "            for i, input in enumerate(inputs):\n",
    "                if input in components:\n",
    "                    node_inputs[node][i] = complex\n",
    "                    continue\n",
    "        node_inputs[node] = list(set(node_inputs[node]))\n",
    "    return node_inputs\n",
    "\n",
    "node_inputs # get OR'd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_components # get AND'd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check complex to complex\n",
    "\n",
    "complex_inputs = {}\n",
    "for complex, components in complex_components.items():\n",
    "    inputs = []\n",
    "    for component in components:\n",
    "        inputs+=node_inputs[component]\n",
    "    complex_inputs[complex] = inputs\n",
    "complex_inputs=reduce_complexes(complex_inputs, complex_components)\n",
    "for complex, inputs in complex_inputs.items():\n",
    "    inputs.remove(complex)\n",
    "complex_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complex_inputs(node_inputs, complex_components):\n",
    "    complex_inputs = {}\n",
    "    for complex, components in complex_components.items():\n",
    "        inputs = []\n",
    "        for component in components:\n",
    "            inputs+=node_inputs[component]\n",
    "        complex_inputs[complex] = list(set(inputs))\n",
    "    complex_inputs=reduce_complexes(complex_inputs, complex_components)\n",
    "    for complex, inputs in complex_inputs.items():\n",
    "        inputs.remove(complex)\n",
    "    return complex_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    complex_inputs = get_complex_inputs(node_inputs, complex_components)\n",
    "\n",
    "complex_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write export helper functions\n",
    "\n",
    "def string2definition2(tabular_text_output, complexes, initial_value):\n",
    "    df = pd.read_csv(tabular_text_output)\n",
    "    df_complexes = pd.read_csv(complexes)\n",
    "\n",
    "    # get list of nodes \n",
    "    nodes = list(df.node1.unique())\n",
    "    \n",
    "    # build dict of node inputs\n",
    "    node_inputs = {}\n",
    "    for node in nodes:\n",
    "        inputs = list(df[df.node1 == node].node2)\n",
    "        node_inputs[node] = inputs\n",
    "        \n",
    "    # get list of complexes \n",
    "    complexes = list(df_complexes.complex.unique())\n",
    "\n",
    "    # build dict of components\n",
    "    complex_components = {}\n",
    "    for complex in complexes:\n",
    "        inputs = list(df_complexes[df_complexes.complex == complex].node)\n",
    "        complex_components[complex] = inputs\n",
    "\n",
    "    # add complex inputs\n",
    "    complex_inputs = get_complex_inputs(node_inputs, complex_components)\n",
    "    \n",
    "    # reduce complexes\n",
    "    node_inputs = reduce_complexes(node_inputs, complex_components)\n",
    "    \n",
    "    # OR node inputs\n",
    "    rules = []\n",
    "    for node, inputs in node_inputs.items():\n",
    "        rule = node + ' *= '\n",
    "        rule = rule + ' or '.join(inputs)\n",
    "        rules.append(rule)\n",
    "        \n",
    "    # AND complex components\n",
    "    for complex, components in complex_components.items():\n",
    "        rule = complex + ' *= '\n",
    "        rule = rule + ' and '.join(components)\n",
    "        rules.append(rule)\n",
    "    \n",
    "    # OR complex inputs\n",
    "    for complex, inputs in complex_inputs.items():\n",
    "        rule = complex + ' *= '\n",
    "        rule = rule + complex + ' or '+' or '.join(inputs)\n",
    "        rules.append(rule)\n",
    "        \n",
    "    # initial conditions\n",
    "    initial_value = 'True' if initial_value else 'False'\n",
    "    initial_conditions = []\n",
    "    for node in (nodes+complexes):\n",
    "        initial_condition = node + ' = ' + initial_value\n",
    "        initial_conditions.append(initial_condition)\n",
    "        \n",
    "    # definition\n",
    "    definition = '#initial conditions\\n'+'\\n'.join(initial_conditions)+'\\n\\n#rules\\n'+'\\n'.join(rules)\n",
    "    \n",
    "    return definition\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definition2 = string2definition2('string-network-1.csv', 'string-1-complexes.csv', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print definition2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_process_edgelist2(definition, edgelist, complexes, initial_value):\n",
    "    df = pd.read_csv(edgelist)\n",
    "    df_complexes = pd.read_csv(complexes)\n",
    "\n",
    "    # get list of nodes\n",
    "    nodes = df.process.unique()\n",
    "\n",
    "    # build dict of node inputs\n",
    "    node_inputs = {}\n",
    "    for node in nodes:\n",
    "        inputs = list(df[df.process == node].node)\n",
    "        node_inputs[node] = inputs\n",
    "    \n",
    "    # get list of complexes \n",
    "    complexes = list(df_complexes.complex.unique())\n",
    "\n",
    "    # build dict of components\n",
    "    complex_components = {}\n",
    "    for complex in complexes:\n",
    "        inputs = list(df_complexes[df_complexes.complex == complex].node)\n",
    "        complex_components[complex] = inputs\n",
    "    \n",
    "    \n",
    "    \n",
    "    # reduce complexes\n",
    "    node_inputs = reduce_complexes(node_inputs, complex_components)\n",
    "    \n",
    "    # construct boolean rules as list\n",
    "    rules = []\n",
    "    for key, value in node_inputs.items():\n",
    "        rule = key + ' *= '\n",
    "        rule = rule + ' and '.join(value)\n",
    "        rules.append(rule)\n",
    "        \n",
    "    # initial conditions\n",
    "    initial_value = 'True' if initial_value else 'False'\n",
    "    initial_conditions = []\n",
    "    for node in (nodes):\n",
    "        initial_condition = node + ' = ' + initial_value\n",
    "        initial_conditions.append(initial_condition)\n",
    "        \n",
    "    # definition\n",
    "    return definition + '\\n\\n#process node initial conditions\\n'+'\\n'.join(initial_conditions)+'\\n\\n#process node rules\\n'+'\\n'.join(rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print add_process_edgelist2(definition2, 'string-1-process-edgelist.csv', 'string-1-complexes.csv', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rp1",
   "language": "python",
   "name": "rp1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
